# Reinforcement Fine-Tuning with OpenR1-Math-220k Dataset

This cookbook demonstrates how to fine-tune language models using **Reinforcement Fine-Tuning (RFT)** with the OpenR1-Math-220k dataset on Azure AI. This dataset contains 220,000 advanced mathematical reasoning problems with verified step-by-step solutions, making it ideal for teaching models complex mathematical problem-solving.

## Overview

Reinforcement Fine-Tuning (RFT) is a powerful technique for training language models on tasks where:
- Multiple valid solution paths exist
- Correctness can be verified automatically
- Step-by-step reasoning is crucial
- The task requires structured, multi-hop thinking

This cookbook uses the **OpenR1-Math-220k dataset**, which contains advanced mathematics problems from college-level and competition mathematics with 2-4 verified reasoning traces per problem generated by DeepSeek R1. The problems cover diverse mathematical domains and require detailed chain-of-thought reasoning.

## Dataset Information

**Source**: [OpenR1-Math-220k on Kaggle](https://www.kaggle.com/datasets/alejopaullier/openr1-math-220k) | [Hugging Face](https://huggingface.co/datasets/open-r1/OpenR1-Math-220k)

**Size**: 220,000 mathematical reasoning problems (full dataset)
- **We use**: First 2 parquet files = ~27,000 unique problems
- **Training set**: ~24,000 problems (90% of 27K)
- **Validation set**: ~3,000 problems (10% of 27K)

> **Important**: 
> - The dataset does NOT have a built-in train/validation split
> - Microsoft Foundry has a **500 MB file upload limit**
> - We use only the **first 2 parquet files** to stay under this limit
> - ALL data is REAL - extracted from actual parquet files


**What the Data Contains**:
The OpenR1-Math-220k dataset consists of advanced mathematical problems with verified solutions. Each problem includes:
- **Problem statement**: Complex mathematics question requiring multi-step reasoning
- **Reasoning traces**: 2-4 verified step-by-step solutions showing detailed mathematical thinking
- **Final answer**: Solution clearly marked in `\boxed{}` format
- **Verification status**: 88% verified using Math Verify tool, 12% verified using Llama-3.3-70B-Instruct

**Problem Domains Covered**:
- Algebra and polynomial factorization
- Calculus and optimization
- Probability theory and expected values
- Geometry and trigonometry
- Number theory and combinatorics
- Linear algebra and matrix operations
- Complex numbers and abstract mathematics

**Task Complexity**: 
- Advanced multi-step mathematical reasoning
- Problems require abstract algebraic manipulation
- Multi-hop logical reasoning (typically 5-15 reasoning steps)
- Advanced mathematical concepts beyond basic arithmetic
- Solutions averaging 8k tokens, complex problems up to 16k tokens

**Why RFT is Perfect for This Task**:
- **Multiple valid solution paths**: Many ways to solve each problem
- **Verifiable correctness**: Mathematical answers can be automatically checked
- **Structured reasoning**: Benefits from learning multiple verified approaches
- **Quality over memorization**: Model learns reasoning patterns, not just answers

## What You'll Learn

This cookbook teaches you how to:

1. Download and prepare the OpenR1-Math-220k dataset from Kaggle
2. Convert Parquet files to JSONL format for Microsoft Foundry fine-tuning
3. Set up your Azure AI environment for RFT
4. Create a grading function to evaluate mathematical reasoning quality
5. Configure and launch an RFT fine-tuning job
6. Monitor training progress and model performance
7. Deploy and test your fine-tuned mathematical reasoning model

## Prerequisites

- Azure subscription with Microsoft Foundry project (requires **Azure AI User** role)
- Python 3.9 or higher
- Familiarity with Jupyter notebooks
- Kaggle account to download the OpenR1-Math-220k dataset
- Understanding of basic mathematical concepts

## Supported Models

RFT in Azure AI Foundry supports the following models:

- **o4-mini**
- **gpt-5 (PrPr)**


> **Note**: Model availability may vary by region. Check the [Azure OpenAI model availability](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) page for current regional support.

## Files in This Cookbook

- **README.md**: This file - comprehensive documentation
- **requirements.txt**: Python dependencies required for the cookbook
- **rft_math_reasoning.ipynb**: Step-by-step notebook implementation
- **training.jsonl**: Training dataset
- **validation.jsonl**: Validation dataset

## Quick Start

### 1. Download the Dataset

1. Go to [OpenR1-Math-220k on Kaggle](https://www.kaggle.com/datasets/alejopaullier/openr1-math-220k)
2. Click "Download" to get all 7 Parquet files (~1.45 GB)
3. Extract **only the first 2 files** to the `training_data/` folder:
   - `train-00000-of-00007.parquet`
   - `train-00001-of-00007.parquet`
4. **Delete the remaining 5 files** (train-00002 to train-00006) to stay under Azure's 500 MB limit

> **Note**: We use only 2 files because using 3 files resulted in a training.jsonl file over 500 MB (the Azure upload limit).

### 2. Install Dependencies

```powershell
pip install -r requirements.txt
```

### 3. Prepare the Dataset

Run the one-time data preparation script to convert Parquet files to JSONL:

```powershell
python scripts/prepare_data.py --input_dir ./training_data --output_dir ./
```

This will create:
- `training.jsonl`: ~24,000 examples (409 MB - within Azure 500 MB limit!)
- `validation.jsonl`: ~3,000 examples (46 MB)

**How validation data is created:**
- The script randomly splits the 27,000 problems into 90% train / 10% validation
- Training uses 1 reasoning trace per problem (from the first 90% of problems)
- Validation uses 1 reasoning trace per problem (from the last 10% of problems)
- This ensures no data leakage between train and validation sets

**All data is REAL** - extracted from actual parquet files with NO guessing or hallucination.

After the JSONL files are created, you can delete the Parquet files and the preparation script to save space.

### 4. Set Up Environment Variables

Create a `.env` file in the root of this directory with your Azure credentials:

```env
# Required for RFT Fine-Tuning
AZURE_AI_PROJECT_ENDPOINT=<your-endpoint>
AZURE_SUBSCRIPTION_ID=<your-subscription-id>
AZURE_RESOURCE_GROUP=<your-resource-group>
AZURE_AOAI_ACCOUNT=<your-foundry-account-name>
MODEL_NAME=<your-base-model-name>

# Required for Model Evaluation
AZURE_OPENAI_ENDPOINT=<your-azure-openai-endpoint>
AZURE_OPENAI_KEY=<your-azure-openai-api-key>
DEPLOYMENT_NAME=<your-deployment-name>
```

### 5. Run the Notebook

Open `rft_math_reasoning.ipynb` and follow the step-by-step instructions to:
- Evaluate base model performance on mathematical reasoning
- Set up the grading function for mathematical correctness
- Launch RFT training with optimal hyperparameters
- Monitor training progress
- Deploy and test your fine-tuned model

## Dataset Format

The RFT format for mathematical reasoning follows this structure:

```json
{
  "messages": [
    {
      "role": "system",
      "content": "You are a mathematical reasoning expert. Solve problems with detailed step-by-step thinking and provide final answers in \\boxed{} format."
    },
    {
      "role": "user",
      "content": "The numbers 2, 3, 5, 7, 11, 13 are arranged in a multiplication table with three along the top and three down the left. What is the largest possible sum of the nine entries?"
    },
    {
      "role": "assistant",
      "content": "[Detailed step-by-step reasoning chain showing mathematical thinking, intermediate calculations, and final answer in \\boxed{} format]"
    }
  ]
}
```

Each training example contains:
- **system message**: Instructions for mathematical problem-solving behavior
- **user message**: The mathematical problem statement
- **assistant message**: One of 2-4 verified reasoning traces with step-by-step solution

## Training Configuration

Recommended hyperparameters for RFT with mathematical reasoning:

- **Model**: gpt-4o or o4-mini
- **Epochs**: 2-3 (mathematical reasoning benefits from focused training)
- **Batch Size**: 1-2 (long reasoning chains require careful processing)
- **Learning Rate Multiplier**: 0.5-1.0 (conservative for preserving reasoning ability)
- **Max Tokens**: 16384 (accommodate long reasoning chains)

These can be adjusted based on your computational resources and specific requirements.

## Grading Mathematical Solutions

The grading function for RFT evaluates:

1. **Answer Correctness**: Final answer matches expected result
2. **Reasoning Quality**: Logical progression and mathematical validity
3. **Format Compliance**: Proper use of `\boxed{}` for final answer
4. **Completeness**: All required steps shown with explanations

The grader assigns rewards (0.0 to 1.0) based on these criteria, allowing the model to learn from better reasoning paths.

## Expected Outcomes

After fine-tuning with RFT on OpenR1-Math-220k, your model should:

- Generate detailed step-by-step mathematical reasoning chains
- Solve college-level and competition mathematics problems
- Handle diverse mathematical domains (algebra, calculus, geometry, etc.)
- Produce properly formatted answers with `\boxed{}` notation
- Demonstrate improved logical reasoning and problem decomposition
- Show better performance on multi-hop mathematical reasoning compared to base model
- Generate solutions with clear intermediate steps and explanations

## Monitoring Training

During RFT training, monitor these key metrics:

- **Training Loss**: Should decrease steadily (indicates learning)
- **Validation Loss**: Should track training loss (indicates generalization)
- **Reward Score**: Average grader score on validation set (measures quality)
- **Answer Accuracy**: Percentage of correct final answers
- **Format Compliance**: Percentage following `\boxed{}` format

## Troubleshooting

**Issue**: Parquet files fail to load
- **Solution**: Ensure you downloaded all 7 files and they are not corrupted

**Issue**: Out of memory during data preparation
- **Solution**: Process files one at a time or reduce batch size in the script

**Issue**: Training loss not decreasing
- **Solution**: Reduce learning rate multiplier or increase epochs

**Issue**: Model generates incorrect mathematical steps
- **Solution**: Verify grading function is properly evaluating reasoning quality

## Additional Resources

- [Azure OpenAI Fine-Tuning Documentation](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning)
- [OpenR1-Math-220k Dataset Card](https://huggingface.co/datasets/open-r1/OpenR1-Math-220k)
- [Mathematical Reasoning Best Practices](https://learn.microsoft.com/azure/ai-services/openai/concepts/advanced-prompt-engineering)

## Citation

If you use this dataset in your research, please cite:

```bibtex
@misc{openr1math220k,
  title={OpenR1-Math-220k: A Large-Scale Dataset for Mathematical Reasoning},
  author={Open R1 Team},
  year={2024},
  publisher={Hugging Face},
  howpublished={\url{https://huggingface.co/datasets/open-r1/OpenR1-Math-220k}}
}
```

## License

This cookbook is provided under MIT License. The OpenR1-Math-220k dataset is licensed under Apache 2.0.

---

**Note**: This is an advanced fine-tuning task requiring significant computational resources. Ensure your Azure subscription has adequate quota for fine-tuning large language models with long context lengths.
